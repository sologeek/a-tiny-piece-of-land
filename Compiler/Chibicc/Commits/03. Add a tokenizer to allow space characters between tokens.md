---
title: 03. Add a tokenizer to allow space characters between tokens(a1ab0ff)
---
## Commit 解析

Commit message 透露的信息是需要支持两个 token 之间的空格字符。所以这个 commit 就是定义和使用 Token。

那么什么是 Token？这里涉及到编译原理相关的知识，待补充 #todo

先看 `test.sh` 的变更

```diff
diff --git a/test.sh b/test.sh
index 9550bbc..876e4e2 100755
--- a/test.sh
+++ b/test.sh
@@ -19,5 +19,6 @@ assert() {
 assert 0 0
 assert 42 42
 assert 21 '5+20-4'
+assert 41 ' 12 + 34 - 5 '
 
 echo OK
```

我们还记得上一个 commit 时特别强调过不支持空格，因为迭代字符串过程直接处理运算符和空格会增加 while 循环中的逻辑复杂度。所以现在使用 `Token` 的概念，将 `char` 进一步抽象，连续多个 `char` 可以组成不同 `Token`，`main.c` 在接收到字符串后，先通过 `tokenize` 将字符串转为 `Token` 的链表串，再对 `Token` 链表串进行迭代。

我们先来看 `main.c` 中主函数的大体逻辑：

1. tokenize，将输入字符串 token 化
2. 迭代 Token 生成汇编代码

```c
// 定义 TokenKind
typedef enum {
  TK_PUNCT, // Punctuators 符号
  TK_NUM,   // Numeric literals 字面量数值
  TK_EOF,   // End-of-file markers 文件结束符
} TokenKind;

// 定义 Token
typedef struct Token Token; // 使用 Token 替代 struct Token
struct Token {
  TokenKind kind; // Token kind
  Token *next;    // Next token
  int val;        // If kind is TK_NUM, its value
  char *loc;      // Token location
  int len;        // Token length
};
```

```c
// Create a new token.
static Token *new_token(TokenKind kind, char *start, char *end) {
  Token *tok = calloc(1, sizeof(Token));
  tok->kind = kind;
  tok->loc = start;
  tok->len = end - start;
  return tok;
}
```
### Tokenize 过程

```c
// Tokenize `p` and returns new tokens.
static Token *tokenize(char *p) {
  Token head = {};
  Token *cur = &head;

  while (*p) {
    // Skip whitespace characters.
    if (isspace(*p)) {
      p++;
      continue;
    }

    // Numeric literal
    if (isdigit(*p)) {
      cur = cur->next = new_token(TK_NUM, p, p);
      char *q = p;
      cur->val = strtoul(p, &p, 10);
      // p 是截取数值后的地址，q 是原地址。字符串存储在栈中，栈的增长方向是地址递减的方向，所以是 p - q 获取值所占的大小
      cur->len = p - q;
      continue;
    }

    // Punctuator
    if (*p == '+' || *p == '-') {
      cur = cur->next = new_token(TK_PUNCT, p, p + 1);
      p++;
      continue;
    }

    error("invalid token");
  }

  cur = cur->next = new_token(TK_EOF, p, p);
  return head.next;
}
```

### 汇编生成过程

#todo

## Reference